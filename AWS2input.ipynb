{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc767d22-67d6-4626-a62b-5ded1942fbe6",
   "metadata": {},
   "source": [
    "# AWS2input\n",
    "Author: Anna Baldo - Master thesis - University of Innsbruck & IGF - anna.baldo@student.uibk.ac.at <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc765e-dbe2-4315-9e10-04e61b7ffecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21202c03-0670-49a4-80fc-08dc0e58afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "filepath = 'your own filepath/20171031-20231031_WSS_Corrected.dat'\n",
    "ds = pd.read_csv(filepath, sep = ',', skiprows = [0], parse_dates=True, encoding='latin-1')\n",
    "ds.set_index('TIMESTAMP', inplace=True)\n",
    "ds.index = pd.to_datetime(ds.index, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# clean LWout_corr columns\n",
    "ds['LWout_corr'] = ds['LWout_corr'].where(ds['LWout_overmax_flag'] == 0).dropna()\n",
    "# select only columns for cosipy\n",
    "cols = ['Press_Avg', 'Tair', 'Hum', 'Wspeed', 'Wdir', # 'EisT1', 'EisT2', 'EisT3', 'EisT4',\n",
    "       'SWout_albedo', 'SWin_albedo', 'LWin_corr', 'LWout_corr', 'snow_clean']\n",
    "ds_cosipy = ds[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830afcd1-6663-4804-bca5-c5ca4aa2d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start and end date for cutting precipitation variables\n",
    "start_date = ds_cosipy.index[0].values\n",
    "end_date = ds_cosipy.index[-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f375297-2fab-4ff3-adef-35bddf23658b",
   "metadata": {},
   "source": [
    "## Albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b1cc145-6bb8-444c-a539-0c653abc780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\AppData\\Local\\Temp\\ipykernel_25188\\665369044.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ds_cosipy['Albedo'] = albedo_midday_res\n"
     ]
    }
   ],
   "source": [
    "# Add albaedo variable - used specifically in modified COSIPY version used in the Master thesis\n",
    "\n",
    "# daily\n",
    "albedo_daily = ds_cosipy[['SWout_albedo', 'SWin_albedo']].resample('1d').sum()\n",
    "albedo_daily['Albedo'] = albedo_daily['SWout_albedo'] / albedo_daily['SWin_albedo']\n",
    "\n",
    "# central hours\n",
    "# select albedo from central hours of the day\n",
    "albedo_midday = ds_cosipy[['SWout_albedo', 'SWin_albedo']][((ds_cosipy.index.hour > 8) & (ds_cosipy.index.hour <= 13))]\n",
    "albedo_midday = albedo_midday.resample('1d').sum()\n",
    "albedo_midday['Albedo'] = albedo_midday['SWout_albedo'] / albedo_midday['SWin_albedo']\n",
    "\n",
    "# resample back to 10min so it can be merged with other dataframe\n",
    "albedo_midday_res = albedo_midday['Albedo'].resample('10min').ffill()\n",
    "\n",
    "# select only full days\n",
    "ds_cosipy = ds_cosipy[albedo_midday_res.to_frame().index[0]:albedo_midday_res.to_frame().index[-1]]\n",
    "# add albedo column\n",
    "ds_cosipy['Albedo'] = albedo_midday_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43addb6d-756a-4bc0-a90c-eadc370e8fa1",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89db2d4-163b-4e8d-b2a0-d185a3a6b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total precipitation from lower station - data not available at WSS\n",
    "# Data requested from LWD station Weißsee\n",
    "\n",
    "# Precipitation\n",
    "filepath = \"your own filepath/20170101-20230503_Weißsee_10min_precipitation.dat\"\n",
    "ds_niederschlag = pd.read_csv(filepath)\n",
    "ds_niederschlag.set_index('datetime', inplace=True)\n",
    "ds_niederschlag.index = pd.to_datetime(ds_niederschlag.index, format='%Y-%m-%d %H:%M:%S')\n",
    "ds_niederschlag = ds_niederschlag.rename(columns={\"precip\": \"LWD_obs[mm]\"})\n",
    "\n",
    "# Temperature\n",
    "filepath = \"your own filepath/1_107_Weißsee_Fagge_Lufttemperatur_LT_Basisganglinie.csv\"\n",
    "ds_lufttemperatur = pd.read_csv(filepath, sep = ';', skiprows=11, header=[0], lineterminator='\\n', decimal=',', encoding=\"ISO-8859-1\")\n",
    "\n",
    "cols_to_change = ['Wert']\n",
    "for col in cols_to_change:\n",
    "    ds_lufttemperatur[col] = ds_lufttemperatur[col].astype('str')\n",
    "    ds_lufttemperatur[col] = ds_lufttemperatur[col].str.replace(',', '.')\n",
    "ds_lufttemperatur = ds_lufttemperatur.replace('---', np.nan)\n",
    "ds_lufttemperatur['Wert'] = ds_lufttemperatur['Wert'].astype(float)\n",
    "\n",
    "# set date as index and fix the format. Time is in UTC (checked)\n",
    "ds_lufttemperatur['datetime'] = ds_lufttemperatur['Datum'] + ' ' + ds_lufttemperatur['Uhrzeit']\n",
    "ds_lufttemperatur.set_index(ds_lufttemperatur.datetime, inplace=True)\n",
    "ds_lufttemperatur.index = pd.to_datetime(ds_lufttemperatur.index, format='%d.%m.%Y %H:%M:%S')\n",
    "ds_lufttemperatur = ds_lufttemperatur.drop(['Datum', 'Uhrzeit', 'datetime'], axis=1)\n",
    "\n",
    "ds_lufttemperatur = ds_lufttemperatur.rename(columns={\"Wert\": \"Temperature[°C]\"}) \n",
    "# select only values that have good quality\n",
    "ds_lufttemperatur = ds_lufttemperatur.where(ds_lufttemperatur[\"Qualität\\r\"] == 'Gut\\r').dropna()\n",
    "\n",
    "# Wind speed\n",
    "#folder pattern where all the datasets are:\n",
    "filepath = \"your own filepath/1_107_Weißsee_Fagge_Windgeschwindigkeit_WG_Basisganglinie.csv\"\n",
    "ds_windspeed = pd.read_csv(filepath, sep = ';', skiprows=11, header=[0], lineterminator='\\n', decimal=',', encoding=\"ISO-8859-1\")\n",
    "\n",
    "cols_to_change = ['Wert[m/s]']\n",
    "for col in cols_to_change:\n",
    "    ds_windspeed[col] = ds_windspeed[col].astype('str')\n",
    "    ds_windspeed[col] = ds_windspeed[col].str.replace(',', '.')\n",
    "ds_windspeed = ds_windspeed.replace('---', np.nan)\n",
    "ds_windspeed['Wert[m/s]'] = ds_windspeed['Wert[m/s]'].astype(float)\n",
    "\n",
    "# set date as index and fix the format. Time is in UTC (checked)\n",
    "ds_windspeed['datetime'] = ds_windspeed['Datum'] + ' ' + ds_windspeed['Uhrzeit']\n",
    "ds_windspeed.set_index(ds_windspeed.datetime, inplace=True)\n",
    "ds_windspeed.index = pd.to_datetime(ds_windspeed.index, format='%d.%m.%Y %H:%M:%S')\n",
    "ds_windspeed = ds_windspeed.drop(['Datum', 'Uhrzeit', 'datetime'], axis=1)\n",
    "\n",
    "ds_windspeed = ds_windspeed.rename(columns={\"Wert[m/s]\": \"Wind_speed[m/s]\"}) \n",
    "# select only values that have good quality\n",
    "ds_windspeed = ds_windspeed.where(ds_windspeed[\"Qualität\\r\"] == 'Gut\\r').dropna()\n",
    "\n",
    "# Cut to the same date range\n",
    "ds_lufttemperatur = ds_lufttemperatur[datetime.datetime(start_date):datetime.datetime(end_date)]\n",
    "ds_windspeed = ds_windspeed[datetime.datetime(start_date):datetime.datetime(end_date)]\n",
    "# And resample to 10 min\n",
    "ds_lufttemperatur_res = ds_lufttemperatur.resample('10min').ffill()\n",
    "ds_windspeed_res = ds_windspeed.resample('10min').ffill()\n",
    "\n",
    "# merge datasets\n",
    "ds_temp_wind = pd.concat([ds_lufttemperatur_res, ds_windspeed_res], axis = 1)\n",
    "ds_temp_wind = ds_temp_wind[['Temperature[°C]', 'Wind_speed[m/s]']]\n",
    "precip_kochendorfer = pd.concat([ds_temp_wind, ds_niederschlag], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "acadfbf5-5411-44bd-aae0-fe0e88229bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\AppData\\Local\\Temp\\ipykernel_25188\\3261250760.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ds_cosipy.loc['2017-11-01 00:00:00':'2023-02-06 23:50:00','precip_HEFgradient'] = precip_kochendorfer.values * x_hef\n"
     ]
    }
   ],
   "source": [
    "# APPLY KOCHENDORFER 2017 CORRECTION - UNDERCATCH\n",
    "# from kochendorfer 2017, unschielded sensor:\n",
    "a = 0.063\n",
    "b = 1.22\n",
    "c = 0.66\n",
    "# compute catch efficiency\n",
    "ce = np.exp( (-1*a*precip_kochendorfer['Wind_speed[m/s]']) * (1 - np.arctan(b*precip_kochendorfer['Temperature[°C]']) + c) )\n",
    "precip_kochendorfer['precip_koch2017'] = precip_kochendorfer['LWD_obs[mm]'] / ce\n",
    "\n",
    "# APPLY VERTICAL PRECIPITAITON GRADIENT\n",
    "# From Winter 2023: HEF range over the year months 8-13% -> Average = 10.5%\n",
    "gamma_star_hef = 10.5/100\n",
    "delta_stations = 3499-2480\n",
    "x_hef = ((gamma_star_hef*delta_stations)/10000) + 1\n",
    "ds_cosipy.loc['2017-11-01 00:00:00':'2023-02-06 23:50:00','precip_HEFgradient'] = precip_kochendorfer.values * x_hef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716a6bc-a19d-4cf6-bd04-73fdb75caefb",
   "metadata": {},
   "source": [
    "## Snowfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4afba5b-82dc-494f-bf2f-5fb588db121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\AppData\\Local\\Temp\\ipykernel_25188\\86831278.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ds_cosipy['snowfall'] = temp_sh\n"
     ]
    }
   ],
   "source": [
    "# Compute snowfall from in situ snowheight data\n",
    "\n",
    "# More manual corrections: set to nan an isolated observation that irrealistically impacted on the ffill in January and November\n",
    "ds_cosipy.loc[datetime.datetime(2018,1,4,0,0):datetime.datetime(2018,1,4,0,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2018,1,4,12,0):datetime.datetime(2018,1,4,12,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2018,1,22,23,0):datetime.datetime(2018,1,22,23,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2018,11,18,11,10):datetime.datetime(2018,11,18,11,10), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,6,14,13,40):datetime.datetime(2022,6,14,14,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,6,18,15,0):datetime.datetime(2022,6,18,15,40), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,6,30,18,50):datetime.datetime(2022,6,30,19,10), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,10,6,0):datetime.datetime(2022,7,10,8,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,10,19,30):datetime.datetime(2022,7,10,19,50), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,12,0,0):datetime.datetime(2022,7,12,2,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,18,4,30):datetime.datetime(2022,7,18,4,30), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,19,8,30):datetime.datetime(2022,7,19,10,30), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,19,17,0):datetime.datetime(2022,7,20,0,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,22,0,0):datetime.datetime(2022,7,25,0,0), 'snow_clean'] = np.nan\n",
    "ds_cosipy.loc[datetime.datetime(2022,7,25,0,0):datetime.datetime(2022,9,1,0,0), 'snow_clean'] = np.nan\n",
    "\n",
    "# Extract necessary data\n",
    "snow_base = ds_cosipy[['snow_clean','Tair','Wspeed']]\n",
    "# Very noisy snowheight still, roll with 20h window and then resample back\n",
    "snow_rolling = snow_base.rolling('20h', center = True).mean()\n",
    "snow_rolling = snow_rolling.resample('1h', label = 'right', closed='right').fillna(method='nearest')\n",
    "\n",
    "# Compute the snow water equivalent using COSIPY's computation of fresh snow density\n",
    "temp_sh = snow_rolling.snow_clean.diff()\n",
    "temp_sh = temp_sh.where(temp_sh > 0, 0)\n",
    "density_fresh_snow = np.maximum(109.0+6.0*(snow_rolling.Tair)+26.0*np.sqrt(snow_rolling.Wspeed), 50.0)\n",
    "snow_we = temp_sh*(density_fresh_snow/917.)*1000      # mm we, cosipy uses ice density 917kg/m3, WHY???\n",
    "\n",
    "# Add the computed snowfall to ds_cosipy\n",
    "ds_cosipy['snowfall'] = temp_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfad3218-1581-4f8f-92e5-9b9882a6d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "filepath = 'your own filepath/20171031-20231031_WSS_input.csv'\n",
    "columns = ['Press_Avg', 'Tair', 'Hum', 'Wspeed', 'Wdir', 'SWout_albedo', 'SWin_albedo', 'LWin_corr', 'LWout_corr',\n",
    "       'Albedo', 'precip_HEFgradient', 'snowfall', 'snow_clean']\n",
    "ds_cosipy[columns].to_csv(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
